# LoadTest Demo Application - Quick Start Guide

## Overview

The LoadTest demo application is now complete! Here's what we've built:

### Components
âœ… **FastAPI Backend** - REST API with health checks, metrics, and CRUD operations  
âœ… **React Frontend** - Modern UI with Dashboard, Data Manager, and Task Runner  
âœ… **Celery Workers (x2)** - Background task processing  
âœ… **MongoDB** - Data persistence  
âœ… **Redis** - Message broker and caching  
âœ… **Unified Docker Image** - Single image for backend and workers  
âœ… **Docker Compose** - Complete local development environment

## Quick Start

### 1. Start the Application

```bash
cd /Users/andrejryzikov/loadtest-env-example/app
docker-compose up --build
```

This will:
- Build the backend/worker image
- Build the frontend image
- Start all 6 services (mongodb, redis, backend, 2 workers, frontend)
- Set up networking and health checks

### 2. Access the Application

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs (Interactive Swagger UI)
- **MongoDB**: localhost:27017
- **Redis**: localhost:6379

### 3. Test the Application

#### Via Frontend (http://localhost:3000)

1. **Dashboard Tab**:
   - View system health (MongoDB, Redis, Celery)
   - Monitor metrics (tasks, data entries)

2. **Data Manager Tab**:
   - Create new data entries
   - Edit existing entries
   - Delete entries
   - View all data in a table

3. **Task Runner Tab**:
   - Select task type (Process Data, Generate Report, Simulate Load)
   - Configure parameters
   - Run task and monitor progress
   - View results in real-time

#### Via API

```bash
# Health check
curl http://localhost:8000/api/health

# Create data entry
curl -X POST http://localhost:8000/api/data \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test Entry",
    "description": "My first entry",
    "value": 123.45,
    "status": "active"
  }'

# List data entries
curl http://localhost:8000/api/data

# Run a task
curl -X POST http://localhost:8000/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "task_type": "simulate_load",
    "params": {
      "duration": 10,
      "intensity": "medium"
    }
  }'

# Check task status (replace TASK_ID)
curl http://localhost:8000/api/tasks/TASK_ID
```

## File Structure

```
app/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ celery_app.py        # Celery configuration  
â”‚   â”œâ”€â”€ config.py            # Settings management
â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”œâ”€â”€ database.py          # MongoDB client
â”‚   â”œâ”€â”€ redis_client.py      # Redis client
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py        # API endpoints
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ celery_tasks.py  # Background tasks
â”‚   â”œâ”€â”€ Dockerfile           # Unified container
â”‚   â”œâ”€â”€ entrypoint.sh        # Service selector
â”‚   â””â”€â”€ requirements.txt     # Python deps
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx         # Entry point
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DataManager.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TaskRunner.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts       # API client
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â””â”€â”€ api.ts       # TypeScript types
â”‚   â”œâ”€â”€ Dockerfile           # Multi-stage build
â”‚   â”œâ”€â”€ nginx.conf           # Nginx config
â”‚   â”œâ”€â”€ package.json         # Node deps
â”‚   â””â”€â”€ vite.config.ts       # Vite config
â”‚
â”œâ”€â”€ docker-compose.yml       # Local development
â””â”€â”€ README.md                # Documentation
```

## How It Works

### Unified Image Strategy

The backend and workers use the **same Docker image** but run different services based on the `SERVICE_TYPE` environment variable:

```yaml
# Backend service
environment:
  - SERVICE_TYPE=backend

# Worker service  
environment:
  - SERVICE_TYPE=worker
  - WORKER_CONCURRENCY=4
```

The `entrypoint.sh` script checks `SERVICE_TYPE` and starts:
- `backend` â†’ `uvicorn main:app --host 0.0.0.0 --port 8000`
- `worker` â†’ `celery -A celery_app worker --loglevel=info`
- `beat` â†’ `celery -A celery_app beat --loglevel=info`

**Benefits**:
- Single build pipeline
- Consistent dependencies
- Guaranteed code consistency
- Simplified version management

### Request Flow

1. User interacts with React frontend (http://localhost:3000)
2. Frontend sends API request to FastAPI backend (http://localhost:8000)
3. Backend processes request:
   - **Sync**: Query MongoDB, return response
   - **Async**: Queue task in Redis, return task ID
4. Celery workers pull tasks from Redis
5. Workers process tasks and store results
6. Frontend polls for task status

## Available Tasks

### 1. Process Data
Simulates data processing with progress tracking.

**Parameters**:
- `data_id` (string): ID to process
- `processing_time` (int): Duration in seconds

### 2. Generate Report
Generates different types of reports.

**Parameters**:
- `report_type` (string): summary, detailed, or analytics

### 3. Simulate Load
Simulates system load for testing.

**Parameters**:
- `duration` (int): Duration in seconds
- `intensity` (string): low, medium, or high

## Troubleshooting

### Services won't start
```bash
# Check service logs
docker-compose logs backend
docker-compose logs worker1
docker-compose logs frontend

# Restart specific service
docker-compose restart backend
```

### Frontend can't connect to backend
- Ensure backend is running: `docker-compose ps`
- Check backend health: `curl http://localhost:8000/api/health`
- Verify VITE_API_URL in frontend service

### Tasks not processing
- Check if workers are running: `docker-compose ps worker1 worker2`
- View worker logs: `docker-compose logs worker1`
- Verify Redis connection: `docker-compose logs redis`

### Database connection issues
- Check MongoDB health: `docker-compose ps mongodb`
- View MongoDB logs: `docker-compose logs mongodb`

## Stopping the Application

```bash
# Stop all services
docker-compose down

# Stop and remove volumes (deletes all data)
docker-compose down -v

# Stop specific service
docker-compose stop backend
```

## Next Steps

Now that the application is running locally, proceed to:

1. âœ… **Test Application** - Verify all features work
2. ðŸ“¦ **Create Helm Chart** - Package for Kubernetes
3. ðŸš€ **Deploy to K8s** - Deploy using Helm
4. ðŸ”„ **Setup ArgoCD** - Configure GitOps workflow
5. ðŸ“Š **Add Monitoring** - Integrate with Prometheus/Grafana

## Development Workflow

### Making Backend Changes

1. Edit backend files
2. Rebuild backend service: `docker-compose up -d --build backend worker1 worker2`
3. View logs: `docker-compose logs -f backend`

### Making Frontend Changes

1. Edit frontend files
2. Rebuild frontend service: `docker-compose up -d --build frontend`
3. View logs: `docker-compose logs -f frontend`

### Adding New Tasks

1. Add task function to `backend/tasks/celery_tasks.py`
2. Import in `backend/api/routes.py`
3. Add to task_map in create_task endpoint
4. Rebuild: `docker-compose up -d --build backend worker1 worker2`

## Support

For issues or questions:
- Check logs: `docker-compose logs <service_name>`
- View running services: `docker-compose ps`
- Inspect service: `docker-compose exec <service_name> sh`
